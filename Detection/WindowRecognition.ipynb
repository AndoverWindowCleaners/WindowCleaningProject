{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9fUj-K8CRUUd"
   },
   "source": [
    "# Set up environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3MtB_wE5RfJV"
   },
   "source": [
    "**Import libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Vi5nR1RhRNw4"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.data import Dataset\n",
    "from tensorflow.keras import callbacks\n",
    "import numpy as np\n",
    "import cv2\n",
    "import copy\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "JkoCknbItEEK"
   },
   "outputs": [],
   "source": [
    "def image_pooling(image, new_width, new_height):\n",
    "    return cv2.resize(image, (new_height, new_width), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "def computeRollingVarianceSum(mean, prev_mean, cur, last):\n",
    "    return  (cur - prev_mean) * (cur - mean) - (last - prev_mean) * (last - mean)\n",
    "\n",
    "def swapPositions(li, pos1, pos2):\n",
    "    li[pos1],li[pos2] = li[pos2],li[pos1]\n",
    "    return li\n",
    "def push_down(li):\n",
    "    for i in range(len(li)-1):\n",
    "        swapPositions(li, i, i+1)\n",
    "     #list[-1] is untouched\n",
    "    return li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ndHuQSdSsaeF"
   },
   "outputs": [],
   "source": [
    "def getVariances(video_path, frame_width=128, frame_height=128, target_frame_width=28, target_frame_height=28):\n",
    "    \"\"\"\n",
    "    video_path is the file path to the input video\n",
    "    Uses functions in the github\n",
    "\n",
    "    Returns:\n",
    "    (diff_variances, input_variances)\n",
    "    \"\"\"\n",
    "\n",
    "    rotation_frequency = 150  # enter in revolution per second\n",
    "\n",
    "    # say the input frames are periodic and can be described by a*sin(bx+c)+d\n",
    "    # its derivative is a*b*cos(bx+c)\n",
    "    # its second derivative is -a*b*b*sin(bx+c)\n",
    "    # so f(x)-f'(x-pi/(2*b))/b should be constant so should f(x)+f\"(x)/b/b\n",
    "    # the second is much better because the first involves a phase shift which\n",
    "    # requires access to data taken pi/(2*b) ago and will thus lower the processing\n",
    "    # speed or accuracy.\n",
    "    # the key is to know b, which is equal to frequency*2pi\n",
    "    frequency_const = rotation_frequency*2*np.pi\n",
    "\n",
    "    num_frame = 5\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(5)\n",
    "    total_frames = int(cap.get(7))-num_frame+1\n",
    "    print('Video loaded with', total_frames,'frames')\n",
    "\n",
    "    input_frame = [np.zeros((target_frame_width,target_frame_height),dtype=np.float32) for i in range(num_frame+1)]\n",
    "    input_mean = np.zeros((target_frame_width,target_frame_height),dtype=np.float32)\n",
    "    input_var_sum = np.zeros((target_frame_width,target_frame_height),dtype=np.float32)\n",
    "\n",
    "    derivative1 = [np.zeros((target_frame_width,target_frame_height),dtype=np.float32) for i in range(num_frame)]\n",
    "    derivative2 = [np.zeros((target_frame_width,target_frame_height),dtype=np.float32) for i in range(num_frame-1)]\n",
    "\n",
    "    diff = [np.zeros((target_frame_width,target_frame_height),dtype=np.float32) for i in range(num_frame-1)]\n",
    "    diff_mean = np.zeros((target_frame_width,target_frame_height),dtype=np.float32)\n",
    "    diff_var_sum = np.zeros((target_frame_width,target_frame_height),dtype=np.float32)\n",
    "\n",
    "    input_vars = np.zeros((int(cap.get(7)),target_frame_width,target_frame_height),dtype=np.float32)\n",
    "    diff_vars = np.zeros((int(cap.get(7)),target_frame_width,target_frame_height),dtype=np.float32)\n",
    "\n",
    "    deltaTime = 1.0/fps\n",
    "    for i in range(int(cap.get(7))):\n",
    "        ret, frame = cap.read()\n",
    "        assert ret\n",
    "        # shallow copy !!!\n",
    "        prev_input_mean = copy.deepcopy(input_mean)\n",
    "        prev_diff_mean = copy.deepcopy(diff_mean)\n",
    "\n",
    "        input_frame = push_down(input_frame)\n",
    "        frame = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "        frame = image_pooling(frame, target_frame_width, target_frame_height)\n",
    "        del_input_frame = copy.deepcopy(input_frame[-1])\n",
    "        input_frame[-1]=frame\n",
    "        input_mean = (input_mean*(num_frame+1) + frame - del_input_frame)/(num_frame+1)\n",
    "        # 1 2 3 3 4 6\n",
    "        #  1 2 3 4 5\n",
    "        #   3 4 5 6\n",
    "        derivative1 = push_down(derivative1)\n",
    "        derivative1[-1]=(input_frame[-1]-input_frame[-2])/deltaTime\n",
    "        derivative2 = push_down(derivative2)\n",
    "        derivative2[-1]=(derivative1[-1]-derivative1[-2])/deltaTime\n",
    "\n",
    "        diff = push_down(diff)\n",
    "        del_diff = copy.deepcopy(diff[-1])\n",
    "        diff[-1] = input_frame[-2]+derivative2[-1]/(frequency_const**2)\n",
    "        diff_mean = (diff_mean*(num_frame-1) + diff[-1] - del_diff)/(num_frame-1)\n",
    "\n",
    "\n",
    "        input_var_sum += computeRollingVarianceSum(input_mean, prev_input_mean, input_frame[-1], del_input_frame)\n",
    "\n",
    "        diff_var_sum += computeRollingVarianceSum(diff_mean, prev_diff_mean, diff[-1], del_diff)\n",
    "\n",
    "        input_var_sum2 = np.var(np.asarray(input_frame), axis=0)\n",
    "        diff_var_sum2 = np.var(np.asarray(diff), axis=0)\n",
    "\n",
    "        input_vars[i] = input_var_sum/(num_frame+1)\n",
    "        diff_vars[i] = diff_var_sum/(num_frame-1)\n",
    "    return diff_vars, input_vars\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "d0yZoO9XJFnt"
   },
   "outputs": [],
   "source": [
    "def variancesToDataset(diff_variance,input_variance,window_location, batch_size=16):\n",
    "    \"\"\"\n",
    "    diff_variance and input_variance are three dimensional numpy arrays, with third dimension being frame number\n",
    "    Before inputting into this function, stack every frame from all images to diff_variance and input_variance\n",
    "    window_location is binary for whether or not there is a window at a pixel in a certain frame\n",
    "\n",
    "    Returns:\n",
    "    Dataset\n",
    "    \"\"\"\n",
    "    features = np.transpose(np.array((diff_variance.flatten(),input_variance.flatten())))\n",
    "    data = (features,window_location.flatten())\n",
    "    ds = Dataset.from_tensor_slices(data)\n",
    "    return ds.batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "WebR5JGWIzih"
   },
   "outputs": [],
   "source": [
    "def get2D(diff_variances, input_variances):\n",
    "    \"\"\"\n",
    "    diff_variance and input_variance are three dimensional numpy arrays, with third dimension being frame number\n",
    "    Before inputting into this function, stack every frame from all images to diff_variance and input_variance\n",
    "    \n",
    "    Returns:\n",
    "    2d numpy array with [variance, variance] as each row\n",
    "    \"\"\"\n",
    "    return np.transpose(np.array((diff_variances.flatten(),input_variances.flatten())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 393
    },
    "id": "gDz1qKrtSxXl",
    "outputId": "07a77a06-01c6-4889-f550-963be6fbef37",
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video loaded with 383 frames\n",
      "Video loaded with 1990 frames\n"
     ]
    }
   ],
   "source": [
    "diff1, input1 = getVariances('outdoor_window_Trim.mp4')\n",
    "diff2, input2 = getVariances('indoor.avi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "id": "4uP7g_3q70XI",
    "outputId": "8bbcca6d-edda-4ad3-a82c-405f93781c24"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.7371960e-03, 1.2534722e+03], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features1 = get2D(diff1,input1)\n",
    "features2 = get2D(diff2,input2)\n",
    "features2 = features2[:features1.shape[0]]\n",
    "features = np.concatenate((features1, features2))\n",
    "features[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels1 = np.ones(features1.shape[0])\n",
    "labels2 = np.zeros(features2.shape[0])\n",
    "labels = np.concatenate((labels1,labels2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "303408"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "az5JZK3kEeUY"
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    tf.keras.layers.Dense(16, activation='relu', input_shape=(2,)),\n",
    "    tf.keras.layers.Dense(8, activation='relu'),\n",
    "    tf.keras.layers.Dense(4,activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "model.compile(optimizer='adam',loss=loss,metrics=[\"acc\", tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "id": "LiOyhO5WGBcA",
    "outputId": "051a7a68-7f54-4b72-9ce6-aa2faca894dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_27 (Dense)             (None, 16)                48        \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 225\n",
      "Trainable params: 225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219
    },
    "id": "WsgT17HtGHVH",
    "outputId": "f663b283-9228-4e85-9954-ee6a37d835eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "30341/30341 [==============================] - 158s 5ms/step - loss: 0.5471 - acc: 0.8037 - precision_1: 0.8198 - recall_1: 0.8801 - val_loss: 0.6328 - val_acc: 0.7289 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\n",
      "Epoch 2/100\n",
      "30341/30341 [==============================] - 134s 4ms/step - loss: 0.3668 - acc: 0.8276 - precision_1: 0.8608 - recall_1: 0.8639 - val_loss: 0.6554 - val_acc: 0.7033 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\n",
      "Epoch 3/100\n",
      "30341/30341 [==============================] - 143s 5ms/step - loss: 0.3603 - acc: 0.8320 - precision_1: 0.8626 - recall_1: 0.8700 - val_loss: 0.5977 - val_acc: 0.7400 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\n",
      "Epoch 4/100\n",
      "30341/30341 [==============================] - 142s 5ms/step - loss: 0.3582 - acc: 0.8320 - precision_1: 0.8648 - recall_1: 0.8666 - val_loss: 0.5837 - val_acc: 0.7516 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\n",
      "Epoch 5/100\n",
      "30341/30341 [==============================] - 142s 5ms/step - loss: 0.3587 - acc: 0.8325 - precision_1: 0.8656 - recall_1: 0.8665 - val_loss: 0.6029 - val_acc: 0.7302 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\n",
      "Epoch 6/100\n",
      "30341/30341 [==============================] - 152s 5ms/step - loss: 0.3574 - acc: 0.8332 - precision_1: 0.8638 - recall_1: 0.8704 - val_loss: 0.6051 - val_acc: 0.7527 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\n",
      "Epoch 7/100\n",
      "30341/30341 [==============================] - 2620s 86ms/step - loss: 0.3556 - acc: 0.8331 - precision_1: 0.8650 - recall_1: 0.8692 - val_loss: 0.6348 - val_acc: 0.7267 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\n",
      "Epoch 8/100\n",
      " 7758/30341 [======>.......................] - ETA: 1:21 - loss: 0.3541 - acc: 0.8336 - precision_1: 0.8643 - recall_1: 0.8717"
     ]
    }
   ],
   "source": [
    "stopper = callbacks.EarlyStopping(monitor='val_loss',patience=10)\n",
    "checkpoint = callbacks.ModelCheckpoint('checkpoint.h5', save_best_only=True)\n",
    "model.fit(\n",
    "    features,\n",
    "    labels,\n",
    "    batch_size=16, \n",
    "    epochs=100, \n",
    "    validation_split=0.2,\n",
    "    callbacks=[stopper, checkpoint],\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "ATpiXIQFUJRN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: simpleLogistic\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('simpleLogistic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.51041037],\n",
       "       [0.5322899 ],\n",
       "       [0.5762917 ],\n",
       "       [0.4887278 ],\n",
       "       [0.6200098 ],\n",
       "       [0.2815646 ],\n",
       "       [0.2134802 ],\n",
       "       [0.26657256],\n",
       "       [0.12947643],\n",
       "       [0.8538543 ]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(features[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.4049049e-03, 2.4568057e+03],\n",
       "       [2.8182040e-03, 2.0334723e+03],\n",
       "       [3.1537088e-03, 2.2755554e+03],\n",
       "       [3.5602415e-03, 2.5688889e+03],\n",
       "       [3.3032717e-03, 2.3834722e+03],\n",
       "       [3.2031783e-03, 2.3112500e+03],\n",
       "       [2.5456422e-03, 1.8368057e+03],\n",
       "       [2.1627853e-03, 1.5605557e+03],\n",
       "       [2.6349563e-03, 1.9012500e+03],\n",
       "       [2.5456422e-03, 1.8368057e+03]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[200:210]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "WindowRecognition.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
