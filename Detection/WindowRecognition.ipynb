{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9fUj-K8CRUUd"
   },
   "source": [
    "# Set up environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3MtB_wE5RfJV"
   },
   "source": [
    "**Import libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Vi5nR1RhRNw4"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.data import Dataset\n",
    "from tensorflow.keras import callbacks\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "JkoCknbItEEK"
   },
   "outputs": [],
   "source": [
    "def image_pooling(image, new_width, new_height, cvt_color):\n",
    "    img =  cv2.resize(image, (new_width, new_height), interpolation=cv2.INTER_AREA)\n",
    "    if cvt_color:\n",
    "        return cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "      return img\n",
    "\n",
    "def computeRollingVariance(square_sum, sum, num_elements):\n",
    "    return (square_sum/num_elements-(sum/num_elements)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ndHuQSdSsaeF"
   },
   "outputs": [],
   "source": [
    "def getVariances(video_path, frame_width=128, frame_height=128, target_frame_width=28, target_frame_height=28):\n",
    "    \"\"\"\n",
    "    video_path is the file path to the input video\n",
    "    Uses functions in the github\n",
    "\n",
    "    Returns:\n",
    "    (diff_variances, input_variances)\n",
    "    \"\"\"\n",
    "    num_frame = 5\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(5)\n",
    "    total_frames = int(cap.get(7))-num_frame+1\n",
    "    print('Video loaded with', total_frames,'frames')\n",
    "\n",
    "    diff_variances = np.zeros((total_frames,target_frame_height,target_frame_width),dtype=np.float64)\n",
    "    input_variances = np.zeros((total_frames,target_frame_height,target_frame_width),dtype=np.float64)\n",
    "    #Constants below\n",
    "    input_frames = np.zeros((num_frame, frame_height, frame_width), dtype=np.float32)\n",
    "    derivative1 = np.zeros((2, frame_height, frame_width), dtype=np.float32)\n",
    "    cur_derivative2_corrected = np.zeros((frame_height, frame_width), dtype=np.float32)\n",
    "    differences = np.zeros((num_frame, frame_height, frame_width), dtype=np.float32)\n",
    "    start_frame = 0\n",
    "    rotation_frequency = 1\n",
    "    frequency_const = rotation_frequency*2*np.pi\n",
    "    difference_sum = np.sum(differences,axis=0)\n",
    "    difference_square_sum = np.sum(np.square(differences),axis=0)\n",
    "    input_sum = np.sum(input_frames,axis=0)\n",
    "    input_square_sum = np.sum(np.square(input_frames),axis=0)\n",
    "    frame_num=0\n",
    "    start_time = time.time()\n",
    "    delta_time = 1\n",
    "    started = False\n",
    "    # Next part loops through each frame in video\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            input_sum -= input_frames[start_frame]\n",
    "            input_square_sum -= np.square(input_frames[start_frame])\n",
    "            difference_sum -= differences[start_frame-1]\n",
    "            difference_square_sum -= np.square(differences[start_frame-1])\n",
    "            # read in image\n",
    "            input_frames[start_frame] = image_pooling(\n",
    "                frame, frame_width, frame_height, True)/255\n",
    "\n",
    "            # compute first derivative\n",
    "            derivative1[start_frame % 2] = (input_frames[start_frame]-input_frames[(start_frame-1)])/delta_time\n",
    "\n",
    "            # compute second derivative and correct its coefficient\n",
    "            cur_derivative2_corrected = (derivative1[start_frame % 2]-derivative1[(start_frame-1) % 2])/delta_time\n",
    "            cur_derivative2_corrected /= frequency_const**2\n",
    "\n",
    "            # compute difference between image and its second derivative. It's actually a +\n",
    "            # because of the negative sign from differentiation\n",
    "            differences[start_frame-1] = cur_derivative2_corrected + \\\n",
    "                input_frames[(start_frame-1)]\n",
    "\n",
    "            # add in new variance of the newly read in image and newly computed difference\n",
    "            input_sum += input_frames[start_frame]\n",
    "            input_square_sum += input_frames[start_frame]**2\n",
    "            difference_sum += differences[start_frame-1]\n",
    "            difference_square_sum += differences[start_frame-1]**2\n",
    "\n",
    "            # recompute variances\n",
    "            input_variance = computeRollingVariance(input_square_sum,input_sum,num_frame)\n",
    "            variances = computeRollingVariance(difference_square_sum,difference_sum,num_frame)\n",
    "            # note this is only an estimation of variance, not the actual variance, which may be difficult\n",
    "            # to evaluate on a rolling basis\n",
    "\n",
    "            # scale down variance to ensure connectiveness\n",
    "            diff_variances[frame_num] = image_pooling(\n",
    "                variances, target_frame_width, target_frame_height, False)\n",
    "            input_variances[frame_num] = image_pooling(\n",
    "                input_variance, target_frame_width, target_frame_height, False)\n",
    "            start_frame = (start_frame+1) % num_frame\n",
    "        else:\n",
    "            break\n",
    "        if start_frame == 0 :\n",
    "            started = True\n",
    "        if started :\n",
    "            frame_num += 1\n",
    "        delta_time = time.time()-start_time\n",
    "        start_time = time.time()\n",
    "    cap.release()\n",
    "    return diff_variances, input_variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "d0yZoO9XJFnt"
   },
   "outputs": [],
   "source": [
    "def variancesToDataset(diff_variance,input_variance,window_location, batch_size=16):\n",
    "    \"\"\"\n",
    "    diff_variance and input_variance are three dimensional numpy arrays, with third dimension being frame number\n",
    "    Before inputting into this function, stack every frame from all images to diff_variance and input_variance\n",
    "    window_location is binary for whether or not there is a window at a pixel in a certain frame\n",
    "\n",
    "    Returns:\n",
    "    Dataset\n",
    "    \"\"\"\n",
    "    features = np.transpose(np.array((diff_variance.flatten(),input_variance.flatten())))\n",
    "    data = (features,window_location.flatten())\n",
    "    ds = Dataset.from_tensor_slices(data)\n",
    "    return ds.batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WebR5JGWIzih"
   },
   "outputs": [],
   "source": [
    "def get2D(diff_variances, input_variances):\n",
    "    \"\"\"\n",
    "    diff_variance and input_variance are three dimensional numpy arrays, with third dimension being frame number\n",
    "    Before inputting into this function, stack every frame from all images to diff_variance and input_variance\n",
    "    \n",
    "    Returns:\n",
    "    2d numpy array with [variance, variance] as each row\n",
    "    \"\"\"\n",
    "    return np.transpose(np.array((diff_variances.flatten(),input_variances.flatten())))"
   ]
  },
  {
   "source": [
    "Preprocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 393
    },
    "id": "gDz1qKrtSxXl",
    "outputId": "07a77a06-01c6-4889-f550-963be6fbef37"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Video loaded with 215 frames\n"
     ]
    }
   ],
   "source": [
    "diff, input = getVariances('Clock_Face_2Videvo.mov')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "id": "4uP7g_3q70XI",
    "outputId": "8bbcca6d-edda-4ad3-a82c-405f93781c24"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(168560, 2)"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "features = get2D(diff,input)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "az5JZK3kEeUY"
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    #tf.keras.layers.Dense(2, activation='relu', input_shape=(2,)),\n",
    "    layers.Dense(1, activation='sigmoid',input_shape=(2,))\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "id": "LiOyhO5WGBcA",
    "outputId": "051a7a68-7f54-4b72-9ce6-aa2faca894dc"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_1 (Dense)              (None, 1)                 3         \n=================================================================\nTotal params: 3\nTrainable params: 3\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219
    },
    "id": "WsgT17HtGHVH",
    "outputId": "f663b283-9228-4e85-9954-ee6a37d835eb"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "2107/2107 - 1s - loss: 0.1546 - accuracy: 1.0000 - val_loss: 0.0567 - val_accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "2107/2107 - 1s - loss: 0.0327 - accuracy: 1.0000 - val_loss: 0.0174 - val_accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "2107/2107 - 1s - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "2107/2107 - 1s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "2107/2107 - 1s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 9.9711e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "2107/2107 - 1s - loss: 6.7642e-04 - accuracy: 1.0000 - val_loss: 4.0092e-04 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8edd249210>"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "stopper = callbacks.EarlyStopping(monitor='val_accuracy',patience=5)\n",
    "model.fit(\n",
    "    features,\n",
    "    np.zeros(features.shape[0]),\n",
    "    batch_size=64, \n",
    "    epochs=100, \n",
    "    validation_split=0.2,\n",
    "    callbacks=[stopper],\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "ATpiXIQFUJRN"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From /Users/michaelhyh/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /Users/michaelhyh/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: simpleLogistic/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('simpleLogistic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.00146401, 0.00052735, 0.00065494, 0.00053045, 0.00186622,\n",
       "       0.00169724, 0.00168318, 0.00253487, 0.00287482, 0.00096923],\n",
       "      dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "output = model.predict(features[:10])\n",
    "output.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "WindowRecognition.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}